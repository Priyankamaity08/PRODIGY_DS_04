import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')
import os
     

col=['Id' , 'Entity' , 'Sentiment' , 'Content']
df_train=pd.read_csv(r"C:\Users\PRIYANKA\Downloads\archive (1)\twitter_training.csv" , names=col)
     

df_test=pd.read_csv(r"C:\Users\PRIYANKA\Downloads\archive (1)\twitter_validation.csv" , names=col)
     

df_train
df_train.shape
df_train.columns
df_train.info()
df_train.dtypes
df_train.isnull().sum()
df_train.dropna(subset=['Content'] , inplace=True)
     

df_train.shape
df_train.Sentiment.unique()
df_train.Sentiment=df_train.Sentiment.replace('Irrelevant' , 'Neutral')
df_test.Sentiment=df_test.Sentiment.replace('Irrelevant' , 'Neutral')
     

df_train.Sentiment.unique()
sentiment_count=df_train.Sentiment.value_counts()
sentiment_count
y=['Neutral' , 'Negative' , 'Positive']
plt.pie(sentiment_count , labels=y, autopct='%0.1f%%' )
circle=plt.Circle((0,0),0.4, facecolor='white')
plt.gca().add_patch(circle)
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
df_train.Entity.unique()

Entity_count=df_train.Entity.value_counts()
Entity_count
Entity_sort=Entity_count.sort_values(ascending=False)
     

Entity_top10=Entity_sort.head(10)
Entity_top10
Entity_index=Entity_top10.index
     

plt.figure(figsize=(13,5))

x=['ApexLegends' , 'WorldOfCraft' , 'Dota2' , 'Microsoft' , 'Facebook' , 'TomClancysRainbowSix' , 'Verizon' , 'CallOfDuty' , 'LeagueOfLegends' , 'MaddenNFL']
y=[2353,2357,2359,2361,2362,2364,2365,2367,2377,2377]

plt.bar( x , y , alpha=0.7 , color='#A2625D')

for i,v in enumerate(y):
    plt.text(i,v,str(v),ha='center',weight='bold' )

plt.xticks(rotation=45)
plt.xlabel('Entity')
plt.ylabel('Number of Post in twitter')
plt.show()
Entity_top3_df=Entity_sort.head(3)
Entity_top3_df
Entity_top3=Entity_top3_df.index.tolist()
Entity_top3
sentiment_by_entity=df_train.loc[df_train['Entity'].isin(Entity_top3)].groupby('Entity')['Sentiment'].value_counts().sort_index()
sentiment_by_entity
plt.figure(figsize=(10,5))

y=['Neutral' , 'Negative' , 'Positive']
color=['#9C6383' , '#839C63' , '#63839C']

plt.subplot(1,3,1)
plt.pie(sentiment_by_entity[:3] , labels=y , autopct='%0.1f%%' , textprops={'fontsize':10} , colors=color)

plt.subplot(1,3,2)
plt.pie(sentiment_by_entity[3:6] , labels=y , autopct='%0.1f%%' , textprops={'fontsize':10} , colors=color)

plt.subplot(1,3,3)
plt.pie(sentiment_by_entity[6:] , labels=y , autopct='%0.1f%%' , textprops={'fontsize':10} , colors=color)

plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left' , fontsize="10")
df_train.drop(['Id'] , axis=1 , inplace=True)
     

df_test.drop(['Id'] , axis=1 , inplace=True)
     

#train test split
X_train=df_train.drop(['Sentiment'] , axis=1)
X_test=df_test.drop(['Sentiment'] , axis=1)
y_train=df_train['Sentiment']
y_test=df_test['Sentiment']
     

df_train.Sentiment.unique()
#count the no of words in a sentence
from sklearn.feature_extraction.text import CountVectorizer
     

v=CountVectorizer()
X_train_count=v.fit_transform(X_train.Content)
     

#label Encoding
from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
y_train=le.fit_transform(y_train)
y_test=le.fit_transform(y_test)
     

y_train
X_train.drop(['Entity'],axis=1,inplace=True)
X_test.drop(['Entity'],axis=1,inplace=True)
     

#model
from sklearn.naive_bayes import MultinomialNB
model=MultinomialNB()
model.fit(X_train_count,y_train)
comment=[
    'I am coming to the borders and I will kill you.'
]
comment_count=v.transform(comment)
model.predict(comment_count)
X_test_count=v.transform(X_test.Content)
X_test_count.toarray()
X_test_count.shape
#score
model.score(X_test_count,y_test)
     
